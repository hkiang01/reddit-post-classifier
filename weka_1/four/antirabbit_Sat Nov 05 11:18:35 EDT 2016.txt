I am currently using a pretty weak GPU (1 GB VRAM) and a low sample size (57 image classes, ~ 20-100 samples per class) for an image sketching application on my website. **[Link to application](http://maxcandocia.com/app/sketch-and-guess/)**. All of the training data is crowd-sourced from submissions within the application.

The images are 400x400, and they are shrunk down to 200x200. For some reason, the best performance I have gotten is starting with a 15x15 convolution with a 6x6 pooling layer with a 4x4 stride.

[Layer 1](http://imgur.com/EV4YILx) has an interesting pattern where every other column and row tends to be zero in the convolution (probably due to redundant information and regularization).

Here is [layer 2](http://imgur.com/eQA3enk) and [layer 3](http://imgur.com/ernf3yi).

I currently have a series of linear and nonlinear distortions for input images to artificially increase the sample size, and I've combined dropout, momentum, stochastic gradient descent, and a small L2 regularization in the network. All of the layers use tanh activation.

I am planning on purchasing better hardware in the near future, but smaller networks are somewhat ideal because the application on my website uses a CPU and is not extremely powerful.

**[Source code](https://github.com/mcandocia/SketchClassification)**

Does anyone have any feedback or questions about the network architecture or the application?