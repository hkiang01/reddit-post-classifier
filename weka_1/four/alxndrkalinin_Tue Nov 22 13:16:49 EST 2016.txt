 Google Research Blog The latest news from Research at Google Zero-Shot Translation with Google’s Multilingual Neural Machine Translation System Tuesday, November 22, 2016 Posted by Mike Schuster (Google Brain Team), Melvin Johnson (Google Translate) and Nikhil Thorat (Google Brain Team) In the last 10 years, Google Translate has grown from supporting just a few languages to 103, translating over 140 billion words every day. To make this possible, we needed to build and maintain many different systems in order to translate between any two languages, incurring significant computational cost. With neural networks reforming many fields, we were convinced we could raise the translation quality further, but doing so would mean rethinking the technology behind Google Translate. In September, we announced that Google Translate is switching to a new system called Google Neural Machine Translation (GNMT), an end-to-end learning framework that learns from millions of examples, and provided significant improvements in translation quality. However, while switching to GNMT improved the quality for the languages we tested it on, scaling up to all the 103 supported languages presented a significant challenge. In “Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation”, we address this challenge by extending our previous GNMT system, allowing for a single system to translate between multiple languages. Our proposed architecture requires no change in the base GNMT system, but instead uses an additional “token” at the beginning of the input sentence to specify the required target language to translate to. In addition to improving translation quality, our method also enables “Zero-Shot Translation” — translation between language pairs never seen explicitly by the system. Here’s how it works. Let’s say we train a multilingual system with Japanese⇄English and Korean⇄English examples, shown by the solid blue lines in the animation. Our multilingual system, with the same size as a single GNMT system, shares its parameters to translate between these four different language pairs. This sharing enables the system to transfer the “translation knowledge” from one language pair to the others. This transfer learning and the need to translate between multiple languages forces the system to better use its modeling power. This inspired us to ask the following question: Can we translate between a language pair which the system has never seen before? An example of this would be translations between Korean and Japanese where Korean⇄Japanese examples were not shown to the system. Impressively, the answer is yes — it can generate reasonable Korean⇄Japanese translations, even though it has never been taught to do so. We call this “zero-shot” translation, shown by the yellow dotted lines in the animation. To the best of our knowledge, this is the first time this type of transfer learning has worked in Machine Translation. The success of the zero-shot translation raises another important question: Is the system learning a common representation in which sentences with the same meaning are represented in similar ways regardless of language — i.e. an “interlingua”? Using a 3-dimensional representation of internal network data, we were able to take a peek into the system as it translates a set of sentences between all possible pairs of the Japanese, Korean, and English languages. Part (a) from the figure above shows an overall geometry of these translations. The points in this view are colored by the meaning; a sentence translated from English to Korean with the same meaning as a sentence translated from Japanese to English share the same color. From this view we can see distinct groupings of points, each with their own color. Part (b) zooms in to one of the groups, and part (c) colors by the source language. Within a single group, we see a sentence with the same meaning but from three different languages. This means the network must be encoding something about the semantics of the sentence rather than simply memorizing phrase-to-phrase translations. We interpret this as a sign of existence of an interlingua in the network. We show many more results and analyses in our paper, and hope that its findings are not only interesting for machine learning or machine translation researchers but also to linguists and others who are interested in how multiple languages can be processed by machines using a single system. Finally, the described Multilingual Google Neural Machine Translation system is running in production today for all Google Translate users. Multilingual systems are currently used to serve 10 of the recently launched 16 language pairs, resulting in improved quality and a simplified production architecture. Google Labels: Google Brain , Google Translate , Machine Learning , Machine Translation , TensorFlow    Labels  accessibility ACL ACM Acoustic Modeling Adaptive Data Analysis ads adsense adwords Africa AI Algorithms Android API App Engine App Inventor April Fools Art Audio Australia Automatic Speech Recognition Awards Cantonese China Chrome Cloud Computing Collaboration Computational Imaging Computational Photography Computer Science Computer Vision conference conferences Conservation correlate Course Builder crowd-sourcing CVPR Data Center data science datasets Deep Learning DeepDream DeepMind distributed systems Diversity Earth Engine economics Education Electronic Commerce and Algorithms electronics EMEA EMNLP Encryption entities Entity Salience Environment Europe Exacycle Expander Faculty Institute Faculty Summit Flu Trends Fusion Tables gamification Gmail Google Books Google Brain Google Cloud Platform Google Docs Google Drive Google Genomics Google Play Apps Google Science Fair Google Sheets Google Translate Google Trips Google Voice Search Google+ Government grants Graph Hardware HCI Health High Dynamic Range Imaging ICLR ICML ICSE Image Annotation Image Classification Image Processing Inbox Information Retrieval internationalization Internet of Things Interspeech IPython Journalism jsm jsm2011 K-12 KDD Klingon Korean Labs Linear Optimization localization Machine Hearing Machine Intelligence Machine Learning Machine Perception Machine Translation MapReduce market algorithms Market Research ML MOOC Multimodal Learning NAACL Natural Language Processing Natural Language Understanding Network Management Networks Neural Networks Ngram NIPS NLP open source operating systems Optical Character Recognition optimization osdi osdi10 patents ph.d. fellowship PhD Fellowship PiLab Policy Professional Development Proposals Public Data Explorer publication Publications Quantum Computing renewable energy Research Research Awards resource optimization Robotics schema.org Search search ads Security and Privacy Semi-supervised Learning SIGCOMM SIGMOD Site Reliability Engineering Social Networks Software Speech Speech Recognition statistics Structured Data Style Transfer Supervised Learning Systems TensorFlow Translate trends TTS TV UI University Relations UNIX User Experience video Video Analysis Vision Research Visiting Faculty Visualization VLDB Voice Search Wiki wikipedia WWW YouTube  Archive      2016 Nov Oct Sep Aug Jul Jun May Apr Mar Feb Jan     2015 Dec Nov Oct Sep Aug Jul Jun May Apr Mar Feb Jan     2014 Dec Nov Oct Sep Aug Jul Jun May Apr Mar Feb Jan     2013 Dec Nov Oct Sep Aug Jul Jun May Apr Mar Feb Jan     2012 Dec Oct Sep Aug Jul Jun May Apr Mar Feb Jan     2011 Dec Nov Sep Aug Jul Jun May Apr Mar Feb Jan     2010 Dec Nov Oct Sep Aug Jul Jun May Apr Mar Feb Jan     2009 Dec Nov Aug Jul Jun May Apr Mar Feb Jan     2008 Dec Nov Oct Sep Jul May Apr Mar Feb     2007 Oct Sep Aug Jul Jun Feb     2006 Dec Nov Sep Aug Jul Jun Apr Mar Feb Feed Googleon Follow @googleresearch Give us feedback in our Product Forums. Company-wide Official Google Blog Public Policy Blog Student Blog Products Android Blog Chrome Blog Lat Long Blog Developers Developers Blog Ads Developer Blog Android Developers Blog Google Privacy Terms 