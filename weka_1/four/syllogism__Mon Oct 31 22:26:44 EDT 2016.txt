This directory contains an implementation of the entailment prediction model described by Parikh et al. (2016). The model is notable for its competitive performance with very few parameters. The model is implemented using Keras and spaCy. Keras is used to build and train the network. spaCy is used to load the GloVe vectors, perform the feature extraction, and help you apply the model at run-time. The following demo code shows how the entailment model can be used at runtime, once the hook is installed to customise the method of spaCy's and objects: I'm working on a blog post to explain Parikh et al.'s model in more detail. I think it is a very interesting example of the attention mechanism, which I didn't understand very well before working through this paper. There are lots of ways to extend the model. First, install Keras, spaCy and the spaCy English models (about 1GB of data): You'll also want to get keras working on your GPU. This will depend on your set up, so you're mostly on your own for this step. If you're using AWS, try the NVidia AMI. It made things pretty easy. Once you've installed the dependencies, you can run a small preliminary test of the Keras model: This compiles the model and fits it with some dummy data. You should see that both tests passed. You can run the directory as a script, which executes the file keras_parikh_entailment/__main__.py. The first thing you'll want to do is train the model: Training takes about 300 epochs for full accuracy, and I haven't rerun the full experiment since refactoring things to publish this example â€” please let me know if I've broken something. You should get to at least 85% on the development data. The other two modes demonstrate run-time usage. I never like relying on the accuracy printed by methods. I never really feel confident until I've run a new process that loads the model and starts making predictions, without access to the gold labels. I've therefore included an mode. Finally, there's also a little demo, which mostly exists to show you how run-time usage will eventually look. We should have the blog post explaining the model ready before the end of the week. To get notified when it's published, you can either the follow me on Twitter, or subscribe to our mailing list.