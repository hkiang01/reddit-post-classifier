I would like to train a model to predict 'word2vec' representations for a given image. The input image contains a single object. Currently, the model uses Glove/word2vec as output. Currently, the nearest neighbors for a predicted word2vec could be 'any' part of the speech. Instead, is it possible to train a customized model which captures word2vec style relationships but is confined to nouns ? That way, the word2vec dictionary (and predictions) can be confined to object names (and their synonyms or closely related concepts). One possibility is to use WordNet, but confined to only the noun senses. Any suggestions/ideas ?

