The YOLO (https://arxiv.org/pdf/1506.02640v5.pdf) detector last layer is a fully connected layer that regresses a 7x7x30 output, representing detections in each cell in a 7x7 grid.
Isn't there a lot of redundancy here? 

If you know how to regress the bounding box for a single cell in that grid, can't that be re-used for all the cells in the grid? 
Why learn a different set of weights for each cell?

Or from another angle - if the training data never contains detections in some of the cells in the grid - won't that cause YOLO to never detect anything in those cells?

You could replace that layer with a convolutional layer, so you get parameter sharing across the image.

I guess this is why the SSD detector uses convolutional layers to regress the bounding boxes.

Is this correct or am I missing something?