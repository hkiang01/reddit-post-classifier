For the detailed experiment scripts and output logs, please refer to this repo. We use 3 data set to conduct our comparison experiments. Details of data are listed in the following table: We use one Linux server as experiment platform, details are listed in the following table: We use xgboost as baseline, and build version is latest version at 27 OCT 2016 016ab89. Both xgboost and LightGBM are built with OpenMP support. We set up total 3 settings for experiments, the parameters of these settings are listed in the following: xgboost grows tree depth-wise and controls model complexity by . LightGBM uses leaf-wise algorithm instead and controls model complexity by . So we cannot compare them in the exact same model setting. For the tradeoff, we use xgboost with , which will have max number leaves to 255, to compare with LightGBM with . And xgboost_approx with will have #bins to 250, which is similar to default(255) in LightGBM. For speed comparison, we only run the training task, which is without any test or metric output. And we don't count the time for IO. The following table is the comparison of time cost: We found LightGBM is faster than xgboost on all experiment data sets. For accuracy comparison, we use the accuracy on test data set to have a fair comparison. We found LightGBM has better accuracy than xgboost on all experiment data sets. We monitor while running training task. And we set (Will increase data-loading time, but reduce peak memory usage, not affect training speed or accuracy) in LightGBM to reduce peak memory usage. LightGBM benefits from its histogram optimization algorithm, so it consumes much lower memory. We use a terabyte click log dataset to conduct parallel experiments. Details are listed in following table: This data contains 13 integer features and 26 category features of 24 days click log. We statistic the CTR and count for these 26 category features from the first ten days, then use next ten daysâ€™ data, which had been replaced the category features by the corresponding CTR and count, as training data. The processed training data hava total 1.7 billions records and 67 features. We use 16 windows servers as experiment platform, details are listed in following table: We use data parallel here, since this data is large in #data but small in #feature. From the results, we find LightGBM perform linear speed up in parallel learning.