 Cornell University Library We gratefully acknowledge support from the Simons Foundation and member institutions arXiv.org > cs > arXiv:1611.05431 All papers Titles Authors Abstracts Full text Help pages (Help | Advanced search) Full-text links: Download: PDF Other formats (license) Current browse context: cs.CV < prev | next > new | recent | 1611 Change to browse by: cs References & Citations NASA ADS DBLP - CS Bibliography listing | bibtex Saining Xie Ross B. Girshick Piotr Dollár Zhuowen Tu Kaiming He Bookmark (what is this?) Computer Science > Computer Vision and Pattern Recognition Title: Aggregated Residual Transformations for Deep Neural Networks Authors: Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He (Submitted on 16 Nov 2016) Abstract: We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call "cardinality" (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, codenamed ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. Comments: Tech report Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:1611.05431 [cs.CV]   (or arXiv:1611.05431v1 [cs.CV] for this version) Submission history From: Kaiming He [view email] [v1] Wed, 16 Nov 2016 20:34:42 GMT (1073kb,D) Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) Link back to: arXiv, form interface, contact. 