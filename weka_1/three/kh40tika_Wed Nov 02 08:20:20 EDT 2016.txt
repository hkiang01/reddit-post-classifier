We found training CNN with a fixed untrainable 3x3 convolution followed by a trainable 1x1 convolution(technically just a GEMM) can improve CNN training convergence speed while requiring less computation. Currently this is supported with empirical evidence on small datasets including MNIST and CIFAR10. While the scalability of this method remains to be confirmed. Above experiment was run on same overall model architechture, with only difference being convolution layer. Yeah I know that is not quite close to state of art, but the point is to compare and provide empirical evidence. The code is written to run experiment with MNIST or CIFAR10 dataset. You should modify the code if you want to test on other datasets. For MNIST, go to here and download all 4 .gz files, save them in . Uncompress them, then run in the same folder. MNIST dataset should be ready to go. For CIFAR10, go to here and download the python version, place it in . Just uncompress it and CIFAR10 dataset should be ready to go. To view help on hyperparameters setting. NOTE: CIFAR10 dataset tend to converge much slower than MNIST, you may want longer training like: training/validation loss curve and model parameters during training will be recorded in file (MATLAB format). Open the file with your favourite tool to analyse. The modified convolution layer takes M image channels and generates 5M image channels via 5 fixed 3x3 convolutions. Then all channels were fed into trainable 1x1 convolution to generate N output channels. 3x3 convolution kernels are following ones: All the above convolution kernels are separable (Note two of them are SOBEL edge detectors). If implemented correctly, this can run much faster than state-of-art generic 3x3 convolution algorithm. We've written a slightly optimized version of this operation with CUDA, in . Thanks to Richard Marko's for doing MNIST preprocessing.