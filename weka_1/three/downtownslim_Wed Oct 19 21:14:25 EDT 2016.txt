 Cornell University Library We gratefully acknowledge support from the Simons Foundation and member institutions arXiv.org > stat > arXiv:1610.05755 All papers Titles Authors Abstracts Full text Help pages (Help | Advanced search) Full-text links: Download: PDF Other formats (license) Current browse context: stat.ML < prev | next > new | recent | 1610 Change to browse by: cs cs.CR cs.LG stat References & Citations NASA ADS Bookmark (what is this?) Statistics > Machine Learning Title: Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data Authors: Nicolas Papernot, Martín Abadi, Úlfar Erlingsson, Ian Goodfellow, Kunal Talwar (Submitted on 18 Oct 2016 (v1), last revised 7 Nov 2016 (this version, v3)) Abstract: Some machine learning applications involve training data that is sensitive, such as the medical histories of patients in a clinical trial. A model may inadvertently and implicitly store some of its training data; careful analysis of the model may therefore reveal sensitive information. To address this problem, we demonstrate a generally applicable approach to providing strong privacy guarantees for training data. The approach combines, in a black-box fashion, multiple models trained with disjoint datasets, such as records from different subsets of users. Because they rely directly on sensitive data, these models are not published, but instead used as "teachers" for a "student" model. The student learns to predict an output chosen by noisy voting among all of the teachers, and cannot directly access an individual teacher or the underlying data or parameters. The student's privacy properties can be understood both intuitively (since no single teacher and thus no single dataset dictates the student's training) and formally, in terms of differential privacy. These properties hold even if an adversary can not only query the student but also inspect its internal workings. Compared with previous work, the approach imposes only weak assumptions on how teachers are trained: it applies to any model, including non-convex models like DNNs. We achieve state-of-the-art privacy/utility trade-offs on MNIST and SVHN thanks to an improved privacy analysis and semi-supervised learning. Comments: Submitted to ICLR 17 Subjects: Machine Learning (stat.ML); Cryptography and Security (cs.CR); Learning (cs.LG) Cite as: arXiv:1610.05755 [stat.ML]   (or arXiv:1610.05755v3 [stat.ML] for this version) Submission history From: Nicolas Papernot [view email] [v1] Tue, 18 Oct 2016 19:37:37 GMT (199kb,D) [v2] Wed, 2 Nov 2016 13:18:56 GMT (199kb,D) [v3] Mon, 7 Nov 2016 00:18:03 GMT (199kb,D) Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) Link back to: arXiv, form interface, contact. 