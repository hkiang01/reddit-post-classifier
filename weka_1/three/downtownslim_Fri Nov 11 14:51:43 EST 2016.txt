 Under review as a conference paper at ICLR 2017 VARIATIONAL RECURRENT ADVERSARIAL DEEP DOMAIN ADAPTATION Sanjay Purushotham*, Wilka Carvalho*, Tanachat Nilanon, Yan Liu Department of Computer Science University of Southern California Los Angeles, CA 90089, USA {spurusho,wcarvalh,nilanon,yanliu.cs}@usc.edu ABSTRACT We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain- invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model’s ability to create domain- invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches. 1 INTRODUCTION Many real-world applications demand effective machine learning algorithms that can learn invariant representations across related time series datasets. For example, precision medicine for patients of various age groups, mobile application recommendation for users based on locations, and so on. In both examples, while the domains (i.e. age group and location) may vary, there exist common predictive patterns that can aid in inferring knowledge from one domain to another. Most often than not, some domains has significantly larger number of observations (e.g., respiratory failure in adults) than others (e.g., respiratory failure in children). Therefore effective domain adaption from time series data are in great demand. The general approach to tackle the domain adaptation has been explored under many facets which include reducing the domain discrepancy between the source and target domains(Ben-David et al. (2007)), instance re-weighting (Jiang & Zhai (2007)), subspace alignment (Fernando et al. (2013)), deep learning (Tzeng et al. (2015); Ganin & Lempitsky (2014)). Many of these approaches work very well for non-sequential data; but however are not suitable for multivariate time series data as they usually not capture the temporal dependencies present in the data. For sequential data, some earlier works successfully used dynamic Bayesian Networks(Huang & Yates (2009)) or Recurrent Neural Networks (Socher et al. (2011)) to learn latent feature representations which were domain-invariant. Unfortunately, these works are not flexible enough to model non-linear dynamics or they do not explicitly capture and transfer the complex latent dependencies needed for domain adaptation of the time series data. In this paper, we address this problem with a model that learns temporal latent dependencies (i.e. dependencies between the latent variables across timesteps) which can be transferred across domains that experience different distributions in their features. It achieves this by using variational methods to produce a latent representation that captures underlying temporal latent dependencies inspired by the Variational Recurrent Neural Network (Chung et al. (2016)) and - motivated by the theory of domain adaptation (Ben-David et al. (2010)) - performs adversarial training on this representation similarly to *: Co-first authors 1 Under review as a conference paper at ICLR 2017 Figure 1: A Story of Temporal Dependency and Domain Invariance (a) DNN (b) DANN (c) VRADA t-SNE projections for the latent representations of DNN, DANN, and our VRADA model for domain adaptation from Adult-AHRF to Child-AHRF dataset. Source data is represented with red circles and target data with blue circles. From left to right, one can see that domain adaptation results in mixing the source and target domain data distributions. We can also see a story of how more temporal dependency being encoded (from left to right) into the latent representation induces more domain-invariant representations (VRADA has better distribution mixing than DANN). As models capture more underlying factors of variation, post domain adaptation representations gradually smoothen and become evenly dispersed, indicating that temporal dependency acts synergestically with domain adaptation. the Domain Adversarial Neural Network (DANN) (Ganin et al. (2016)) to make the representations invariant across domains. We call our model the Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) model. As far as we know, this is the first model capable of accomplishing unsupervised domain adaptation while transferring temporal latent dependencies for the complex multivariate time series data. Figure 1 shows an example of the domain invariant representations learned by different deep learning models including our VRADA model. From this figure, we can see that our model (VRADA) shows better mixing of the domain distributions than the competing models indicating that it learns better domain invariant representations. In order to prove the efficacy of our model, we perform domain adaptation using real-world healthcare time-series data. We choose healthcare data for two primary reasons. (1) Currently, a standard protocol in healthcare is to build, evaluate and deploy machine learning models for particular datasets (e.g. models for particular age groups or particular diseases) which may perform poorly on unseen datasets with different distributions. For example, models built around patient data from particular age groups perform poorly on other age groups because the features used to train the models have different distributions across the groups (Alemayehu & Warner (2004); Lao et al. (2004); Seshamani & Gray (2004))–i.e. knowledge learned from one group is not transferrable to the other group. This is essentially a domain adaptation problem where knowledge needs to be transferred across domains which share features that exhibit different distributions. (2) Healthcare data has multiple attributes recorded per patient visit, and it is longitudinal and episodic in nature. Thus, healthcare data is a suitable platform on which to study a model which seeks to capture complex temporal representations and transfer this knowledge across domains. The rest of the paper is structured as follows. In the following section, we briefly discuss the current state-of-the-art deep domain adaptation approaches. Afterwards, we present our model mathematically, detailing how it captures temporal latent dependencies at the same time and learns domain-invariant representations by adversarial training. In Section 4, we compare and contrast the performance of proposed approach on two real-world health care datasets; and provide analysis on our domain-invariant representations. 2 RELATED WORK Domain adaptation is a specific instance of transfer learning in which the feature spaces are shared but their marginal distributions are different. A good survey on the two has been done in several previous works Pan & Yang (2009); Jiang (2008); Patel et al. (2015). Domain adaptation has been well studied in computer vision(Saenko et al. (2010); Gong et al. (2012); Fernando et al. (2013)) and natural language processing (NLP) (Blitzer (2007); Foster et al. (2010)) applications. Recently, deep learning paradigm has become popular in domain adaptation (Chen et al. (2012); Tzeng et al. (2015); Yang & Eisenstein; Long & Wang (2015)) due to its ability to learn rich, flexible, non-linear domain-invariant 2 Under review as a conference paper at ICLR 2017 h1 h2 h3 ht . . . . . . . . . x1 x2 x3 xt z1 z2 z3 zt Gy Gd Figure 2: Block diagram of VRADA. Blue lines show the inference process, qθe(zt|x≤t, z<t). Brown lines show the generation process, pθg (xt|z≤t, x<t). Red lines show the recurrence process where ht is informed by ht−1, which is informed by zt−1 and xt−1. Black lines indicate classification. representations. Here, we briefly discuss two deep domain adaptation approaches which are closely related to our proposed model. Domain Adversarial Neural Networks (DANN) Ganin et al. (2016) is a deep domain adaptation model which uses two core components to create domain-invariant representations, a feature extractor that produces the data’s latent representation, and an adversarial domain labeler that attempts to classify that data’s domain to help the feature extractor produce latent representations which are domain-invariant. In Louizos et al. (2015), the authors propose Variational Fair AutoEncoder, which uses Variational Autoencoding architecture Kingma & Welling (2013) to learn latent representations where most of the information about certain known factors of variation are purged from the representation while still retaining as much information about the data as possible. While, these deep learning approaches learn domain-invariant representations, they fail to capture and transfer the underlying complex temporal latent relationships from one domain to another as they use convolutional or feed forward neural networks which we claim are not suitable for multivariate time series data. Other works such as Huang & Yates (2009); Xiao & Guo (2013) have used distributed representations for domain adaptation in sequence labeling tasks in NLP. However, they either induce hidden states as latent features using dynamic Bayesian networks (DBNs) (such as hidden Markov Models(HMM)) or learn generalizable distributed representations of words using Recurrent Neural Networks (RNN) (Socher et al. (2011)) to enable domain adaptation. These works either model the highly non-linear dynamics (like RNN) or capture the complex latent dependencies present in sequential data (like DBNs) but not both. To overcome the challenges of DBNs and RNNs, Variational Recurrent Neural Network (VRNN)( Chung et al. (2016)) was proposed recently, to capture the complex relationship between the underlying hidden factors of model variation and the output variables at different time- steps. VRNN uses Variational Autoencoders (VAEs)( Kingma & Welling (2013); Goodfellow et al. (2016)) at each time-step and learns complex relationship of latent hidden factors along time and are thus well-suited for multimodal sequential data such as multivariate time series. In the following section, we discuss our approach, Variational Adversarial Deep Domain Adaptation (VRADA), which uses VRNN to model and transfer complex temporal latent relationships while learning the domain invariant representations for unsupervised domain adaptation in multivariate time series. 3 VARIATIONAL RECURRENT ADVERSARIAL DEEP DOMAIN ADAPTATION In this section, we present our Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) model for the purpose of capturing and transferring temporal latent dependencies across domains via domain-invariant representations. First, we introduce the notations used in this paper and then discuss our VRADA model in detail. 3.1 NOTATIONS Let us denote a multivariate variable-length time series with N data samples as {xi = (xit)T i t=1}Ni=1, where xit ∈ RD. (Note: in our experiments, for all data samples T i = τ , but for generality we maintain T i). We denote {xiS}ni=1 as source domain data and {xiT }Ni=n+1 as target domain data. We assume that each source domain data sample xiS comes with L labels yi ∈ {0, 1}L (for example, these labels may correspond to a clinical outcome such as mortality or ICD9 diagnosis codes), while 3 Under review as a conference paper at ICLR 2017 target domain has no labeled data samples, i.e. we are interested in unsupervised domain adaptation problem. We assign a domain label di ∈ {0, 1} to each data sample to indicate if it comes from the source or target domain. di will be used for adversarial training. 3.2 VRADA The block diagram of our VRADA model is shown in Figure 2. To explicitly model the dependencies between the latent random variable across time steps, the VRADA model utilizes Variational Recurrent Neural Networks (VRNN) (Chung et al. (2016)). VRNN effectively contain Variational Auto- Encoders (Kingma & Welling (2013)) at every time step, which are conditioned on previous auto- encoders via the hidden state ht−1 of an RNN, such as an LSTM (Hochreiter & Schmidhuber (1997)). Therefore, for each time-step of xit, we infer a latent random variable z i t via zit|xit ∼ N (µz,t, diag(σz,t)), where [µz,t, σz,t] = ϕencτ (ϕxτ (xit), ht−1) with prior zit ∼ N (µ0,t, diag(σ0,t)), where [µ0,t, σ0,t] = ϕpriorτ (ht−1) where µ∗,t, σ∗,t denote parameters of a generating distribution, and ϕ∗τ can be any highly flexible function such as deep neural networks. For each zit, x i t is generated via xit|zit ∼ N (µx,t, diag(σx,t)), where [µx,t, σx,t] = ϕdecτ (ϕzτ (zit), ht−1) and learned by optimizing the VRNN objective function: Lr(xit; θe, θg) = Eqθe (zi≤Ti |xi≤Ti )[ T i∑ t=1 (−D(qθe(zit|xi≤t, zi<t)||p(zit|xi<t, zi<t))+log pθg (xit|zi≤t, xi<t))]) where qθe(z i t|xi≤t, zi<t) is the inference model, p(zit|xi<t, zi<t) is the posterior, pθg (xit|zi≤t, xi<t) is the generative model, θe is the parameters of the VRNN’s encoder, θg the parameters of the VRNN’s decoder, and D(·||·) refers to KL-Divergence. Note: z≤T refers to the set of all zt such that t ≤ T , likewise for z<T . For each xi, we use z̃i ∼ qθe(ziT i |x i ≤T i , z i <T i), as our feature representation for source domain classification task since it captures temporal latent dependencies across the time-steps. Training the VRNN for the source domain classification involves solving the following optimization: min θe,θg,θy 1 n n∑ i=1 1 T i Lr(xi; θe, θg) + 1 n n∑ i=1 Ly(xi; θy, θe) + λR(θe) (1) whereR(θe) is a regularizer for the parameters of VRNN encoder (which is also the feature extractor of VRADA) with a tuning hyperparameter λ. As we are interested in achieving domain adaptation via the latent representation z̃i (i.e. to make z̃i domain-invariant), we can adversarially train the above objective function (equation 1) by employing the domain adaptation idea proposed in Ganin et al. (2016). Let Gy(z̃i; θy) and Gd(z̃i; θd) represent the source label classifier (to predict source labels yi) and domain label classifier (to predict domain labels di) respectively with parameters θy and θd for a given input z̃i. Here, Gy(.) and Gd(.) can be deep neural networks. Let us denote their loss functions respectively as Ly(xi; θy, θe) = LB(Gy(Ve(xi; θe); θy), yi); Ld(xi; θd, θe) = LB(Gd(Ve(xi; θe); θd), di) where LB is the classification loss such as a binary or categorical cross-entropy loss function and Ve(x i; θe) is the VRNN encoder that maps input xi to z̃i. Now, for adversarial training, we consider the following domain adaptation term as the regularizer of equation 1. R(θe) = max θd [ − 1 n n∑ i=1 Ld(xi; θd, θe)− 1 n′ N∑ i=n+1 Ld(xi; θd, θe) ] (2) where n′ is the number of target domain samples. As shown in Ganin et al. (2016),R is the domain regularizer and it is derived from the empiricalH−divergence between the source domain and target domain samples( Ben-David et al. (2010)). 4 Under review as a conference paper at ICLR 2017 Combining the joint optimization problem of equations 1 and 2 leads to our VRADA model, where we minimize the source classification risk and at the same time achieve domain adaptation. Mathe- matically, we optimize the following complete objective function: E(θe, θg, θy, θd) = 1 N N∑ i=1 1 T i Lr(xi; θe, θg)+ 1 n n∑ i=1 Ly(xi; θy)−λ( 1 n n∑ i=1 Ld(xi; θd)+ 1 n′ N∑ i=n+1 Ld(xi; θd))) (3) where λ is a trade-off between optimizing on making domain-invariant representations and optimiz- ing source classification accuracy. Our optimization involves minimization with respect to some parameters, and maximization with respect to the others, i.e., we iteratively solve the following: (θ̂g, θ̂y, θ̂e) = arg min θg,θy,θe E(θe, θg, θy, θ̂d) θ̂d = argmax θd E(θ̂e, θ̂g, θ̂y, θd) with the gradient updates calculated as: θe ← θe − η(∂Lr∂θe + ∂Ly ∂θy − λ∂Ld∂θd ) (4) θg ← θg − η ∂Lr∂θg (5) θd ← θd − η ∂Ld∂θd (6) θy ← θy − ηλ∂Ly∂θy (7) where η is the learning rate. We can use stochastic gradient descent (SGD) to solve the equations (5-7). To solve equation (4), we can use SGD and the gradient reversal layer (GRL)(Ganin et al. (2016)). The role of GRL is to reverse the gradient sign while performing backpropagation. This ensures that the domain classification loss is maximized which makes the feature representations domain-invariant. Thus, VRADA results in learning feature representations which are domain-invariant (due to domain regressorR) and which capture the temporal latent dependencies (due to optimizing VRNN objective function Lr). These things combine to allow the VRADAs’ discriminative power on the source domain to transfer to the target domain. 4 EXPERIMENTS We conduct experiments on two real-world health care datasets to answer the following questions: (a) How does our VRADA model perform when compared to the state-of-the-art domain adaptation and non-adaptation approaches? (b) How different are the domain-invariant representations learned by various domain adaptation methods? (c) How do we show that the temporal latent dependencies are transferred between domains? In the remainder of this section, we will describe the datasets, methods, empirical results, and show visualizations to answer the above questions. 4.1 DATASET DESCRIPTION We conduct experiments on two health care datasets, including the MIMIC-III dataset and a Pediatric ICU dataset from Children’s Hospital Los Angeles. MIMIC-III( Johnson et al. (2016)) is a public dataset with deidentified clinical care data collected at Beth Israel Deaconess Medical Center from 2001 to 2012. It contains over 58,000 hospital admission records of 38,645 adults and 7,875 neonates. For our experiments, we extracted the following two datasets: • Adult-AHRF dataset: To study domain adaptation for adult patients with acute hypoxemic respiratory failure (AHRF), we extracted 20 time series features (such as Base excess, pH value, Mean Air Pressure, PaO2, etc.) from 5527 admission records based on Khemani 5 Under review as a conference paper at ICLR 2017 et al. (2009). We grouped the patients into 4 groups/cohorts based on their age[1] - Group 2: working-age adult (20 to 45 yrs, 508 patients); Group 3: old working-age adult (46 to 65 yrs, 1888 patients); Group 4: elderly (66 to 85 yrs, 2394 patients); Group 5: old elderly (85 yrs and up, 437 patients). We treated each group as a separate domain with which we could perform domain adaptation. For each patient, we used the first 4 day after admission (with each day serving as a single time-step) as time series data for training and testing our models. • ICD9 dataset: For this dataset we extracted 99 time series features from 19714 admission records from 4 modalities including input-events (fluids into patient, e.g., insulin), output- events (fluids out of the patient, e.g., urine), lab-events (lab test results, e.g., pH values and platelet count) and prescription-events (drugs prescribed by doctors, e.g., aspirin and potassium chloride). These modalities are known to be extremely useful for monitoring ICU patients. All the time series are of more than 48 hours of duration, and only the first 24 hours (after admission) 2-hourly sampled time series data is used for training and testing our models. We use this dataset to predict the ICD9 Diagnosis code categories for each patient’s admission record. Child-AHRF dataset: This is a PICU dataset which contains health records of 398 children patient with acute hypoxemic respiratory failure in the intensive care unit at Children’s Hospital Los Angeles (CHLA)(Khemani et al. (2009)). Similar to Adult-AHRF, this dataset has 20 time series features collected for 4 days after ICU admission. This dataset is considered as one group (Group 1: children, age 0 to 19 yrs) and represents one domain. 4.1.1 PREDICTION AND DOMAIN ADAPTATION TASKS Mortality Prediction: For Adult-AHRF and Child-AHRF datasets, we are interested in predicting mortality, i.e. whether a patient dies from AHRF during their hospital stay. 20.10% of all the patients in Child-AHRF and 13.84% of all patients in Adult-AHRF have a positive mortality label (i.e. the patients who die in hospital). ICD9 Code Prediction: Each admission record in MIMIC-III dataset has multiple ICD-9 diagnosis codes. We group all the occurrences of the ICD-9 codes into 20 diagnosis groups[2] . For the ICD9 dataset, we are interested in predicting these 20 ICD-9 Diagnosis Categories for each admission record. We treat this as a multi-task prediction problem. Domain Adaptation Tasks: We study unsupervised domain adaptation (i.e. target domain labels are unavailable during training and validation) task with-in age groups of Adult-AHRF dataset, ICD9 dataset and across Adult and Child-AHRF datasets. For Adult-AHRF and ICD9 datasets, we created 12 source-target domain pairs using the age groups, pairing up each domain Di with another domain Dj 6=i, for example, the source-target pair 2-5 was used for adapting from group 2 (working-age adult) to group 5 (old elderly). We also created 4 source-target pairs for performing domain adaptation from 4 adult age-groups to 1 child age-group. 4.2 METHODS AND IMPLEMENTATION DETAILS We categorize the methods use in our main experiments into the following groups: • Non-adaptive baseline methods: Logistic Regression (LR), Adaboost with decision regres- sors (Adaboost), and feed forward deep neural networks (DNN) • Deep Domain adaptation methods: Domain Adversarial Neural Networks (DANN) (Ganin et al. (2016)); DANN with an RNN (LSTM) as feature extractor (R-DANN); Variational Fair Autocoder (VFAE)(Louizos et al. (2015)) • Our method: Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) In all our experiments, we conducted unsupervised domain adaptation where target domain labels are unavailable during training and validation. For R-DANN, we used LSTM(Hochreiter & Schmidhuber [1]:https://www.cms.gov/Research-Statistics-Data-and-Systems/ Statistics-Trends-and-Reports/NationalHealthExpendData/ [2]:“Conditions Originating in the Perinatal Period” is not shown in the preprocessed dataset. http: //tdrdata.com/ipd/ipd_SearchForICD9CodesAndDescriptions.aspx. 6 https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/NationalHealthExpendData/ https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/NationalHealthExpendData/ http://tdrdata.com/ipd/ipd_SearchForICD9CodesAndDescriptions.aspx http://tdrdata.com/ipd/ipd_SearchForICD9CodesAndDescriptions.aspx Under review as a conference paper at ICLR 2017 (1997)) as the feature extractor network instead of the feed-forward neural networks used in DANN. For VFAE, DANN and all the non-domain adaptive approaches we flattened the time series along time axis and treat it as the input to the model. For fairness, the classifier and feature extractors of the VRADA and R-DANN were equivalent in depth and both had the same model capacity. We also ensure that the size of latent feature representation z̃i are similar for VRADA and DANN models. The model capacity of VFAE was chosen to be similar to VRADA. All the deep domain adaptation models including ours had depth of size 8 (including output classifier layers). We used the Adam optimizer ( Kingma & Ba (2014)) and ran all models for 500 epochs with a learning rate of 3e−4. We set an early stopping criteria that the model does not experience a decrease in the validation loss for 20 epochs. Source domain data was split into train/validation subsets with a 70/30 ratio and target domain data into train/validation/test subsets with a 70/15/15 ratio. In order to compare all the methods, we report AUC scores on the entire target domain set, and the test subset for each target domain data of a source-target pair. 4.3 QUANTITATIVE RESULTS In Table 1, we compare non domain adaptation and domain adaptation models’ performance on the target domain test subset for the AHRF mortality prediction task. It is immediately clear that domain adaptation methods consistently outperform non domain adaptation methods. We see that generally the VRADA outperforms both variants of the DANN with it consistently seeing scores ∼ 4% higher. While the standard deviation for the VRADA was about 1%, it was about 2% for the R-DANN, further showing our models efficacy as it converges to more stable local optima. Our model VRADA beats state-of-the-art DANN(Ganin et al. (2016)) and VFAE(Louizos et al. (2015)) on all the source-pair domain adaptation tasks for Adult-AHRF dataset. For the domain adaptation from Adult-AHRF to Child-AHRF dataset, we observe that VRADA mostly outperforms all the competing models. This shows that our model can perform well even for smaller target domain datasets. Table 1: AUC Comparison for AHRF Mortality Prediction task with and without Domain Adaptation Source-Target LR Adaboost DNN DANN VFAE R-DANN VRADA 3- 2 0.555 0.562 0.569 0.572 0.615 0.603 0.654 4- 2 0.624 0.645 0.569 0.589 0.635 0.584 0.656 5- 2 0.527 0.554 0.551 0.540 0.588 0.611 0.616 2- 3 0.627 0.621 0.550 0.563 0.585 0.708 0.724 4- 3 0.681 0.636 0.542 0.527 0.722 0.821 0.770 5- 3 0.655 0.706 0.503 0.518 0.608 0.769 0.782 2- 4 0.585 0.591 0.530 0.560 0.582 0.716 0.777 3- 4 0.652 0.629 0.531 0.527 0.697 0.769 0.764 5- 4 0.689 0.699 0.538 0.532 0.614 0.728 0.738 2- 5 0.565 0.543 0.549 0.526 0.555 0.659 0.719 3- 5 0.576 0.587 0.510 0.526 0.533 0.630 0.721 4- 5 0.682 0.587 0.575 0.548 0.712 0.747 0.775 5- 1 0.502 0.573 0.557 0.563 0.618 0.563 0.639 4- 1 0.565 0.533 0.572 0.542 0.668 0.577 0.636 3- 1 0.500 0.500 0.542 0.535 0.570 0.591 0.631 2- 1 0.520 0.500 0.534 0.559 0.578 0.630 0.637 In the above table, we test classification without adaptation using Logistic Regression (LR), Adaboost with decision tree classifiers and Feed forward Deep Neural Networks (DNN); and with adaptation using Deep Domain Adversarial Neural Networks (DANN), a DANN with an LSTM in its feature extractor (R-DANN), Variational Fair Autoencoder (VFAE) and our Variational Adversarial Domain Adaptation Model (VRADA). All results are reported on the target domain test subset dataset. As the AHRF mortality prediction task made it clear that domain adaptation is necessary for inter- group adaptation, for the ICD9 multi-task prediction task that involved data with time-steps of length 12, we focused strictly on adaptive models (i.e. the DANN, R-DANN, and VRADA). Table 2 shows the aggregated AUC scores on the entire target domain dataset and test data of the target domain for the 20 tasks of the ICD9 Code Prediction task. Here we clearly see that our VRADA model outperforms competing domain adaptive models by significant margins. On numerous adaptation settings the VRADA gets a AUC score of > 0.76 whereas R-DANN obtains AUC score around 0.68 i.e. VRADA outperforms R-DANN by ∼ 8% when averaged over all the source-target domain pairs. 7 Under review as a conference paper at ICLR 2017 Table 2: AUC Comparison for ICD9 Diagnosis Code Prediction task Model 23 24 25 32 34 35 42 43 45 52 53 54 DANN entire targettarget test 0.523 0.530 0.509 0.557 0.513 0.540 0.520 0.571 0.518 0.520 0.524 0.515 0.510 0.561 0.515 0.553 0.535 0.531 0.524 0.534 0.515 0.530 0.518 0.526 R-DANN entire targettarget test 0.691 0.672 0.679 0.677 0.597 0.575 0.704 0.585 0.708 0.732 0.717 0.637 0.754 0.618 0.759 0.806 0.753 0.697 0.688 0.567 0.702 0.720 0.729 0.727 VRADA entire targettarget test 0.741 0.740 0.753 0.755 0.753 0.751 0.716 0.718 0.793 0.792 0.792 0.790 0.708 0.712 0.764 0.765 0.807 0.807 0.703 0.707 0.760 0.762 0.801 0.799 Here, we compare results for the ICD9 Diagnosis Code Prediction task on the ICD9 dataset. For each model, the top row corresponds to the performance on the entire target domain dataset and the bottom row corresponds to performance on the test subset (15%) of the target domain dataset. Further, for difficult adaptation settings such as transferring knowledge learned from young adults to the elderly (2-5), where the DANN and R-DANN perfom poorly, the VRADA consistently performs well on both data (target data) it was exposed to during training (but without labels) and data it never learned to adapt for (the target domain test subset). 4.4 DISCUSSION Figure 3 shows the temporal latent dependencies captured by our VRADA as compared to the R-DANN for 3-4 source-target pair. While both models learn temporal latent dependencies fairly well, the VRADA outperforms the R-DANN in two ways. First, the VRADA’s neurons learned stronger predictions of whether features are relevant towards modeling the data. If we look at the VRADA row, for both AHRF and ICD9 we see that the neural activation patterns are more consistent across time-steps than for R-DANN. Figure 4 shows the unrolled memory cell states (in the form Examples× Time ∗ Neurons) for all the source and target domain data points. We see a consistent activation firing patterns across all these data points for VRADA but not for R-DANN. Together with the stronger performance on 34 for AHRF and 25 for ICD9, this potentially indicates that VARDA is better learning the temporal dependencies. Second, nuanced values are consistent across time-steps for the VRADA, exhibiting a gradual transition towards stronger activation with time, whereas the temporal activation pattern of the R- DANN seems somewhat sporadic. While activation gradients across time are consistent for both the R-DANN and VRADA, more consistent inhibitory and excitatory neuron firing patterns indicate that the VRADA better transfers knowledge. Another indication of domain adaptation was shown in Figure 1c. Looking at the t-SNE projections of feature representations of DNN, R-DANN, and VRADA we can see that the addition of temporal latent dependencies might help in better mixing of the domain distributions since we observe that the data is more evenly spread out. Figure 1c and Figure 3 together indicate that the VRADA’s temporal latent dependency capturing power and ability to create domain-invariant representations act synergistically. 5 SUMMARY Because of the diverse range of patients healthcare data is collected for and its episodic and longitudal nature, healthcare data provides a good platform to test domain adaptation techniques for temporal data. With it as our example, we showcase the Variational Recurrent Adversarial Domain Adaptation (VRADA) model’s ability to learn temporal latent representations that are domain-invariant. By comparing our model’s latent representations to others’, we show its ability to use variational methods to capture hidden factors of variation and produce more robust domain-invariant representations. We hope this work serves as a bedrock for future work capturing and adapting temporal latent representations across domains. ACKNOWLEDGMENTS This material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-1418060. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. We also acknowledge Thailand’s Development and 8 Under review as a conference paper at ICLR 2017 R-DANN 0.5 1 1.5 2 2.5 3 3.5 4 4.5 2 4 6 8 10 12 14 16 18 20 -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 0.5 1 1.5 2 2.5 3 3.5 4 4.5 2 4 6 8 10 12 14 16 18 20 -3 -2 -1 0 1 2 3 VRADA 0.5 1 1.5 2 2.5 3 3.5 4 4.5 2 4 6 8 10 12 14 16 18 20 -3 -2 -1 0 1 2 3 0.5 1 1.5 2 2.5 3 3.5 4 4.5 2 4 6 8 10 12 14 16 18 20 -3 -2 -1 0 1 2 3 Source Target 2 4 6 8 10 12 5 10 15 20 25 30 35 40 -4 -3 -2 -1 0 1 2 3 4 2 4 6 8 10 12 5 10 15 20 25 30 35 40 -3 -2.5 -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 2 4 6 8 10 12 5 10 15 20 25 30 35 40 -10 -8 -6 -4 -2 0 2 4 6 8 10 2 4 6 8 10 12 5 10 15 20 25 30 35 40 -10 -8 -6 -4 -2 0 2 4 6 8 10 Source Target AHRF, 3-4 ICD9, 2-5 Figure 3: Cell states of memory cell for R-DANN and VRADA showing temporal latent dependencies captured by neurons of the R-DANN and VRADA for the source domain and transferred to the target domain. Each step along the y-axis refers to the activation of a single neuron with blue for strong inhibition and yellow for strong excitation. Step along the x-axis refers to activation per time-step. The left shows a single example in adapting 3-4 and the right for adapting 2-5. 50 100 150 200 250 300 350 400 450 50 100 150 200 250 300 350 400 450 -8 -6 -4 -2 0 2 4 6 8 10 50 100 150 200 250 300 350 400 450 50 100 150 200 250 300 350 400 -10 -8 -6 -4 -2 0 2 4 6 8 10 50 100 150 200 250 300 350 400 450 50 100 150 200 250 300 350 400 450 -10 -8 -6 -4 -2 0 2 4 6 8 10 50 100 150 200 250 300 350 400 450 50 100 150 200 250 300 350 400 -10 -8 -6 -4 -2 0 2 4 6 8 10 R-DANN VRADA Figure 4: Cell states of memory cell for R-DANN and VRADA showing activation for all ICD9 2-5 adaptation examples. Here, we show temporal dependencies learned across time, feature pairs for examples in a domain. The y-axis values refer to values per data point and the x-axis shows activation at time, feature pairs with the time and feature dimensions being flattened. Promotion of Science and Technology Talents Project for financial support. We thank Dr. Robinder Khemani for sharing the Child-AHRF dataset. REFERENCES Berhanu Alemayehu and Kenneth E Warner. The lifetime distribution of health care costs. Health services research, 39(3):627–642, 2004. S Ben-David, J Blitzer, and K Crammer. Analysis of representations for domain adaptation. Advances in Neural . . . , pp. 137–144, 2007. Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79(1-2):151–175, 2010. John Blitzer. Domain adaptation of natural language processing systems. PhD thesis, University of Pennsylvania, 2007. Minmin Chen, Zhixiang Xu, Kilian Weinberger, and Fei Sha. Marginalized denoising autoencoders for domain adaptation. arXiv preprint arXiv:1206.4683, 2012. Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron Courville, and Yoshua Bengio. A Recurrent Latent Variable Model for Sequential Data. arXiv.org, May 2016. 9 Under review as a conference paper at ICLR 2017 Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars. Unsupervised visual domain adaptation using subspace alignment. In Proceedings of the IEEE International Conference on Computer Vision, pp. 2960–2967, 2013. George Foster, Cyril Goutte, and Roland Kuhn. Discriminative instance weighting for domain adaptation in statistical machine translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pp. 451–459. Association for Computational Linguistics, 2010. Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. arXiv preprint arXiv:1409.7495, 2014. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The Journal of Machine Learning Research, 17(1), 2016. Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman. Geodesic flow kernel for unsupervised domain adaptation. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 2066–2073. IEEE, 2012. Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. Mit Press, December 2016. Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735–1780, 1997. Fei Huang and Alexander Yates. Distributional representations for handling sparsity in supervised sequence-labeling. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1, pp. 495–503. Association for Computational Linguistics, 2009. Jing Jiang. A literature survey on domain adaptation of statistical classifiers. URL: http://sifaka. cs. uiuc. edu/jiang4/domainadaptation/survey, 2008. Jing Jiang and ChengXiang Zhai. Instance weighting for domain adaptation in nlp. In ACL, volume 7, pp. 264–271, 2007. AEW Johnson, TJ Pollard, L Shen, L Lehman, M Feng, M Ghassemi, B Moody, P Szolovits, LA Celi, and RG Mark. Mimic-iii, a freely accessible critical care database. Scientific Data, 2016. Robinder G Khemani, David Conti, Todd A Alonzo, Robert D Bart III, and Christopher JL Newth. Effect of tidal volume in children with acute hypoxemic respiratory failure. Intensive care medicine, 35(8):1428–1437, 2009. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014. URL http://arxiv.org/abs/1412.6980. Diederik P Kingma and Max Welling. Auto-Encoding Variational Bayes. arXiv.org, December 2013. Zhiqiang Lao, Dinggang Shen, Zhong Xue, Bilge Karacali, Susan M Resnick, and Christos Da- vatzikos. Morphological classification of brains via high-dimensional shape transformations and machine learning methods. Neuroimage, 21(1):46–57, 2004. Mingsheng Long and Jianmin Wang. Learning transferable features with deep adaptation networks. CoRR, abs/1502.02791, 1:2, 2015. Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard Zemel. The variational fair auto encoder. arXiv preprint arXiv:1511.00830, 2015. Sinno Jialin Pan and Qiang Yang. A Survey on Transfer Learning. IEEE Transactions on Knowledge and Data Engineering, 22(10):1345–1359, 2009. Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):53–69, 2015. 10 http://arxiv.org/abs/1412.6980 Under review as a conference paper at ICLR 2017 Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to new domains. In European conference on computer vision, pp. 213–226. Springer, 2010. Meena Seshamani and Alastair M Gray. A longitudinal study of the effects of age and time to death on hospital costs. Journal of health economics, 23(2):217–235, 2004. Richard Socher, Cliff C Lin, Chris Manning, and Andrew Y Ng. Parsing natural scenes and natural language with recursive neural networks. In Proceedings of the 28th international conference on machine learning (ICML-11), pp. 129–136, 2011. Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. In Proceedings of the IEEE International Conference on Computer Vision, pp. 4068–4076, 2015. Min Xiao and Yuhong Guo. Domain adaptation for sequence labeling tasks with a probabilistic language adaptation model. In ICML (1), pp. 293–301, 2013. Yi Yang and Jacob Eisenstein. Unsupervised multi-domain adaptation with feature embeddings. 11 Introduction Related Work Variational Recurrent Adversarial Deep Domain Adaptation Notations VRADA Experiments Dataset Description Prediction and Domain Adaptation tasks Methods and Implementation Details Quantitative Results Discussion Summary 