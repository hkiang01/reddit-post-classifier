 Cornell University Library We gratefully acknowledge support from the Simons Foundation and member institutions arXiv.org > cs > arXiv:1610.02995 All papers Titles Authors Abstracts Full text Help pages (Help | Advanced search) Full-text links: Download: PDF Other formats (license) Current browse context: cs.LG < prev | next > new | recent | 1610 Change to browse by: cs cs.AI References & Citations NASA ADS DBLP - CS Bibliography listing | bibtex Georg Martius Christoph H. Lampert Bookmark (what is this?) Computer Science > Learning Title: Extrapolation and learning equations Authors: Georg Martius, Christoph H. Lampert (Submitted on 10 Oct 2016) Abstract: In classical machine learning, regression is treated as a black box process of identifying a suitable function from a hypothesis set without attempting to gain insight into the mechanism connecting inputs and outputs. In the natural sciences, however, finding an interpretable function for a phenomenon is the prime goal as it allows to understand and generalize results. This paper proposes a novel type of function learning network, called equation learner (EQL), that can learn analytical expressions and is able to extrapolate to unseen domains. It is implemented as an end-to-end differentiable feed-forward network and allows for efficient gradient based training. Due to sparsity regularization concise interpretable expressions can be obtained. Often the true underlying source expression is identified. Comments: 13 pages, 8 figures, 4 tables Subjects: Learning (cs.LG); Artificial Intelligence (cs.AI) MSC classes: 68T05, 68T30, 68T40, 62J02, 65D15 ACM classes: I.2.6; I.2.8 Cite as: arXiv:1610.02995 [cs.LG]   (or arXiv:1610.02995v1 [cs.LG] for this version) Submission history From: Georg Martius [view email] [v1] Mon, 10 Oct 2016 16:47:36 GMT (1884kb,D) Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) Link back to: arXiv, form interface, contact. 