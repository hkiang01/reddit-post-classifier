 Cornell University Library We gratefully acknowledge support from the Simons Foundation and member institutions arXiv.org > cs > arXiv:1611.00712 All papers Titles Authors Abstracts Full text Help pages (Help | Advanced search) Full-text links: Download: PDF Other formats (license) Current browse context: cs.LG < prev | next > new | recent | 1611 Change to browse by: cs stat stat.ML References & Citations NASA ADS DBLP - CS Bibliography listing | bibtex Chris J. Maddison Andriy Mnih Yee Whye Teh Bookmark (what is this?) Computer Science > Learning Title: The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables Authors: Chris J. Maddison, Andriy Mnih, Yee Whye Teh (Submitted on 2 Nov 2016 (v1), last revised 6 Nov 2016 (this version, v2)) Abstract: The reparameterization trick enables optimizing large scale stochastic computation graphs via gradient descent. The essence of the trick is to refactor each stochastic node into a differentiable function of its parameters and a random variable with fixed distribution. After refactoring, the gradients of the loss propagated by the chain rule through the graph are low variance unbiased estimators of the gradients of the expected loss. While many continuous random variables have such reparameterizations, discrete random variables lack continuous reparameterizations due to the discontinuous nature of discrete states. In this work we introduce concrete random variables -- continuous relaxations of discrete random variables. The concrete distribution is a new family of distributions with closed form densities and a simple reparameterization. Whenever a discrete stochastic node of a computation graph can be refactored into a one-hot bit representation that is treated continuously, concrete stochastic nodes can be used with automatic differentiation to produce low-variance biased gradients of objectives (including objectives that depend on the log-probability of latent stochastic nodes) on the corresponding discrete graph. We demonstrate effectiveness of concrete relaxations on density estimation and structured prediction tasks using neural networks. Subjects: Learning (cs.LG); Machine Learning (stat.ML) Cite as: arXiv:1611.00712 [cs.LG]   (or arXiv:1611.00712v2 [cs.LG] for this version) Submission history From: Chris J. Maddison [view email] [v1] Wed, 2 Nov 2016 18:25:40 GMT (662kb,D) [v2] Sun, 6 Nov 2016 23:25:23 GMT (440kb,D) Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) Link back to: arXiv, form interface, contact. 