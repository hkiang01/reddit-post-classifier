 Cornell University Library We gratefully acknowledge support from the Simons Foundation and member institutions arXiv.org > stat > arXiv:1610.05683 All papers Titles Authors Abstracts Full text Help pages (Help | Advanced search) Full-text links: Download: PDF Other formats (license) Current browse context: stat.ML < prev | next > new | recent | 1610 Change to browse by: stat stat.ME References & Citations NASA ADS Bookmark (what is this?) Statistics > Machine Learning Title: Rejection Sampling Variational Inference Authors: Christian A. Naesseth, Francisco J. R. Ruiz, Scott W. Linderman, David M. Blei (Submitted on 18 Oct 2016) Abstract: Variational inference using the reparameterization trick has enabled large-scale approximate Bayesian inference in complex probabilistic models, leveraging stochastic optimization to sidestep intractable expectations. The reparameterization trick is applicable when we can simulate a random variable by applying a (differentiable) deterministic function on an auxiliary random variable whose distribution is fixed. For many distributions of interest (such as the gamma or Dirichlet), simulation of random variables relies on rejection sampling. The discontinuity introduced by the accept--reject step means that standard reparameterization tricks are not applicable. We propose a new method that lets us leverage reparameterization gradients even when variables are outputs of a rejection sampling algorithm. Our approach enables reparameterization on a larger class of variational distributions. In several studies of real and synthetic data, we show that the variance of the estimator of the gradient is significantly lower than other state-of-the-art methods. This leads to faster convergence of stochastic optimization variational inference. Subjects: Machine Learning (stat.ML); Methodology (stat.ME) Cite as: arXiv:1610.05683 [stat.ML]   (or arXiv:1610.05683v1 [stat.ML] for this version) Submission history From: Christian A. Naesseth [view email] [v1] Tue, 18 Oct 2016 15:55:08 GMT (778kb,D) Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) Link back to: arXiv, form interface, contact. 