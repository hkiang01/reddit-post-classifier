 Cornell University Library We gratefully acknowledge support from the Simons Foundation and member institutions arXiv.org > cs > arXiv:1609.04309 All papers Titles Authors Abstracts Full text Help pages (Help | Advanced search) Full-text links: Download: PDF Other formats (license) Current browse context: cs.CL < prev | next > new | recent | 1609 Change to browse by: cs cs.LG References & Citations NASA ADS DBLP - CS Bibliography listing | bibtex Edouard Grave Armand Joulin Moustapha Cissé David Grangier Hervé Jégou Bookmark (what is this?) Computer Science > Computation and Language Title: Efficient softmax approximation for GPUs Authors: Edouard Grave, Armand Joulin, Moustapha Cissé, David Grangier, Hervé Jégou (Submitted on 14 Sep 2016) Abstract: We propose an approximate strategy to efficiently train neural network based language models over very large vocabularies. Our approach, called adaptive softmax, circumvents the linear dependency on the vocabulary size by exploiting the unbalanced word distribution to form clusters that explicitly minimize the expectation of computational complexity. Our approach further reduces the computational cost by exploiting the specificities of modern architectures and matrix-matrix vector operations, making it particularly suited for graphical processing units. Our experiments carried out on standard benchmarks, such as EuroParl and One Billion Word, show that our approach brings a large gain in efficiency over standard approximations while achieving an accuracy close to that of the full softmax. Subjects: Computation and Language (cs.CL); Learning (cs.LG) Cite as: arXiv:1609.04309 [cs.CL]   (or arXiv:1609.04309v1 [cs.CL] for this version) Submission history From: Edouard Grave [view email] [v1] Wed, 14 Sep 2016 15:15:08 GMT (116kb,D) Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) Link back to: arXiv, form interface, contact. 